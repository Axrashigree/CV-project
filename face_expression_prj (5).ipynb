{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3wWNBfJw6RQ",
        "outputId": "655c0f42-aedd-4ffd-89c9-6207a70dd056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: s/content/drive/MyDrive/ALKASHAN: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "Ok!s/content/drive/MyDrive/ALKASHAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO5ZW0y-pMPN",
        "outputId": "0e2429db-7f08-46f7-efdb-f9fac8077e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TPlXHOzGxrr7"
      },
      "outputs": [],
      "source": [
        "#!7za -y x \"/content/drive/MyDrive/DSAI_Prj-1/data/image/origin.7z.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYE6rQkByCqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a4ebbc0-1c13-4494-b36f-48670d38ec47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat './origin': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "#!cp -r ./origin \"/content/drive/MyDrive/DSAI_Prj-1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "_Djm95Fv2xeY"
      },
      "outputs": [],
      "source": [
        "label_file_path=r\"/content/drive/MyDrive/DSAI_Prj-1/data/label/label.lst\"\n",
        "images_folder_path=r\"/content/drive/MyDrive/DSAI_Prj-1/origin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "0xuIdpJ63jHx",
        "outputId": "260ed408-1c34-404d-c557-ef2ce5bba958"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            image_name  face_id_in_image  face_box_top  face_box_left  \\\n",
              "0  angry_actor_104.jpg                 0            28            113   \n",
              "1  angry_actor_109.jpg                 0            31            157   \n",
              "2  angry_actor_120.jpg                 1            53             53   \n",
              "3   angry_actor_13.jpg                 0            77             51   \n",
              "4  angry_actor_132.jpg                 0            95             31   \n",
              "\n",
              "   face_box_right  face_box_bottom  face_box_confidence  expression_label  \n",
              "0             226              141              22.9362                 0  \n",
              "1             345              219              50.3056                 0  \n",
              "2             372              372              13.9434                 2  \n",
              "3             362              388              85.8104                 3  \n",
              "4             412              476              82.3948                 0  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-76a258ac-7b9e-49dc-8147-ef0bae44dde5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>face_id_in_image</th>\n",
              "      <th>face_box_top</th>\n",
              "      <th>face_box_left</th>\n",
              "      <th>face_box_right</th>\n",
              "      <th>face_box_bottom</th>\n",
              "      <th>face_box_confidence</th>\n",
              "      <th>expression_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>angry_actor_104.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>113</td>\n",
              "      <td>226</td>\n",
              "      <td>141</td>\n",
              "      <td>22.9362</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>angry_actor_109.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>157</td>\n",
              "      <td>345</td>\n",
              "      <td>219</td>\n",
              "      <td>50.3056</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>angry_actor_120.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>53</td>\n",
              "      <td>372</td>\n",
              "      <td>372</td>\n",
              "      <td>13.9434</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>angry_actor_13.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>51</td>\n",
              "      <td>362</td>\n",
              "      <td>388</td>\n",
              "      <td>85.8104</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>angry_actor_132.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>95</td>\n",
              "      <td>31</td>\n",
              "      <td>412</td>\n",
              "      <td>476</td>\n",
              "      <td>82.3948</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76a258ac-7b9e-49dc-8147-ef0bae44dde5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-1f6f1460-35bf-4711-af6c-1c142148254a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f6f1460-35bf-4711-af6c-1c142148254a')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-1f6f1460-35bf-4711-af6c-1c142148254a button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76a258ac-7b9e-49dc-8147-ef0bae44dde5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76a258ac-7b9e-49dc-8147-ef0bae44dde5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "from numpy import split\n",
        "import pandas as pd\n",
        "df_info = pd.read_csv(label_file_path, sep=\" \",header=None)\n",
        "col_names=\"image_name face_id_in_image face_box_top face_box_left face_box_right face_box_bottom face_box_confidence expression_label\".split()\n",
        "df_info.columns = col_names\n",
        "\n",
        "df_info.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_info.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xLuPFOqYvsC",
        "outputId": "571aabc4-5ad9-490c-ad15-2954e71df65d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(91793, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "ouUkK3xr5N09"
      },
      "outputs": [],
      "source": [
        "df_sel=df_info[df_info.face_box_confidence>45]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "y9-8yLmLQCtZ",
        "outputId": "28484205-2215-4205-ac86-11c3d5d339d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           image_name  face_id_in_image  face_box_top  \\\n",
              "1                 angry_actor_109.jpg                 0            31   \n",
              "3                  angry_actor_13.jpg                 0            77   \n",
              "4                 angry_actor_132.jpg                 0            95   \n",
              "5                 angry_actor_137.jpg                 0            93   \n",
              "9                 angry_actor_150.jpg                 0            56   \n",
              "...                               ...               ...           ...   \n",
              "91786    surprised_expression_409.jpg                 0            80   \n",
              "91787  expressionless_husband_673.jpg                 0            48   \n",
              "91789    surprised_expression_381.jpg                 0            51   \n",
              "91790    surprised_expression_395.jpg                 0            27   \n",
              "91792    surprised_expression_394.jpg                 0            47   \n",
              "\n",
              "       face_box_left  face_box_right  face_box_bottom  face_box_confidence  \\\n",
              "1                157             345              219              50.3056   \n",
              "3                 51             362              388              85.8104   \n",
              "4                 31             412              476              82.3948   \n",
              "5                468             842              467              88.9519   \n",
              "9                263             376              169              81.8792   \n",
              "...              ...             ...              ...                  ...   \n",
              "91786             46             184              218              63.8069   \n",
              "91787            194             388              242              82.2975   \n",
              "91789             61             117              107              91.6307   \n",
              "91790             95             258              190              96.2861   \n",
              "91792             38             152              161              77.7758   \n",
              "\n",
              "       expression_label  \n",
              "1                     0  \n",
              "3                     3  \n",
              "4                     0  \n",
              "5                     0  \n",
              "9                     0  \n",
              "...                 ...  \n",
              "91786                 5  \n",
              "91787                 4  \n",
              "91789                 5  \n",
              "91790                 5  \n",
              "91792                 5  \n",
              "\n",
              "[51856 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-151f60fd-e243-4e2b-af6a-108737d64a83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>face_id_in_image</th>\n",
              "      <th>face_box_top</th>\n",
              "      <th>face_box_left</th>\n",
              "      <th>face_box_right</th>\n",
              "      <th>face_box_bottom</th>\n",
              "      <th>face_box_confidence</th>\n",
              "      <th>expression_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>angry_actor_109.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>157</td>\n",
              "      <td>345</td>\n",
              "      <td>219</td>\n",
              "      <td>50.3056</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>angry_actor_13.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>51</td>\n",
              "      <td>362</td>\n",
              "      <td>388</td>\n",
              "      <td>85.8104</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>angry_actor_132.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>95</td>\n",
              "      <td>31</td>\n",
              "      <td>412</td>\n",
              "      <td>476</td>\n",
              "      <td>82.3948</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>angry_actor_137.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>93</td>\n",
              "      <td>468</td>\n",
              "      <td>842</td>\n",
              "      <td>467</td>\n",
              "      <td>88.9519</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>angry_actor_150.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>263</td>\n",
              "      <td>376</td>\n",
              "      <td>169</td>\n",
              "      <td>81.8792</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91786</th>\n",
              "      <td>surprised_expression_409.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>46</td>\n",
              "      <td>184</td>\n",
              "      <td>218</td>\n",
              "      <td>63.8069</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91787</th>\n",
              "      <td>expressionless_husband_673.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>194</td>\n",
              "      <td>388</td>\n",
              "      <td>242</td>\n",
              "      <td>82.2975</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91789</th>\n",
              "      <td>surprised_expression_381.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>61</td>\n",
              "      <td>117</td>\n",
              "      <td>107</td>\n",
              "      <td>91.6307</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91790</th>\n",
              "      <td>surprised_expression_395.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>95</td>\n",
              "      <td>258</td>\n",
              "      <td>190</td>\n",
              "      <td>96.2861</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91792</th>\n",
              "      <td>surprised_expression_394.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>38</td>\n",
              "      <td>152</td>\n",
              "      <td>161</td>\n",
              "      <td>77.7758</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51856 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-151f60fd-e243-4e2b-af6a-108737d64a83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-50dae2e3-4434-4d05-82ee-1d07981f1cfc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50dae2e3-4434-4d05-82ee-1d07981f1cfc')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-50dae2e3-4434-4d05-82ee-1d07981f1cfc button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-151f60fd-e243-4e2b-af6a-108737d64a83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-151f60fd-e243-4e2b-af6a-108737d64a83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "df_sel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sel.image_name.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veKxkOQKgUMI",
        "outputId": "8ae7af59-7216-46ee-8573-256c2c49519f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "awe_teacher_108.jpg              112\n",
              "astound_expression_526.jpg        52\n",
              "awe_grandfather_256.jpg           50\n",
              "astound_expression_400.jpg        48\n",
              "amazed_president_890.jpg          46\n",
              "                                ... \n",
              "expressionless_wife_880.jpg        1\n",
              "expressionless_woman_139.jpg       1\n",
              "expressionless_worker_310.jpg      1\n",
              "expressionless_worker_328.jpg      1\n",
              "surprised_expression_394.jpg       1\n",
              "Name: image_name, Length: 40628, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AVuIZ9keCUs",
        "outputId": "71341fcc-9aae-4efe-8a76-f0ead51bc330"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51856, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "df_sel.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "ioZ1-aotROl8"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "x=[]\n",
        "y=[]\n",
        "for i, row in df_sel.iterrows():\n",
        "  img_name=row[\"image_name\"]\n",
        "  x1 = row[\"face_box_left\"]\n",
        "  y1=row[\"face_box_top\"]\n",
        "  x2=row[\"face_box_right\"]\n",
        "  y2=row[\"face_box_bottom\"]\n",
        "  label=row[\"expression_label\"]\n",
        "  img_path=os.path.join(images_folder_path,img_name)\n",
        "\n",
        "  image = cv2.imread(img_path)\n",
        "\n",
        "  #croping\n",
        "  if image is not None:\n",
        "        cropped=image[y1:y2, x1:x2]\n",
        "        face = cv2.resize(cropped, (48, 48))\n",
        "        if face is not None:\n",
        "          x.append(face)\n",
        "          y.append(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.array(x)\n",
        "Y = np.array(y)"
      ],
      "metadata": {
        "id": "T7KexOBE1mzb"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCwX3Awb1tnI",
        "outputId": "0ee7c27d-354f-4088-fc18-501b9a9ca910"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 30,  46,  59],\n",
              "         [ 33,  47,  61],\n",
              "         [ 40,  51,  65],\n",
              "         ...,\n",
              "         [ 92, 100, 114],\n",
              "         [ 96, 104, 117],\n",
              "         [ 62,  71,  81]],\n",
              "\n",
              "        [[ 28,  41,  55],\n",
              "         [ 27,  38,  52],\n",
              "         [ 51,  61,  75],\n",
              "         ...,\n",
              "         [ 87,  94, 110],\n",
              "         [ 90,  97, 112],\n",
              "         [100, 108, 121]],\n",
              "\n",
              "        [[ 34,  45,  59],\n",
              "         [ 30,  40,  54],\n",
              "         [ 66,  75,  89],\n",
              "         ...,\n",
              "         [ 87,  94, 111],\n",
              "         [ 95, 102, 119],\n",
              "         [ 93, 100, 115]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 85,  91, 122],\n",
              "         [ 86,  92, 122],\n",
              "         [ 86,  93, 120],\n",
              "         ...,\n",
              "         [ 31,  47,  64],\n",
              "         [ 44,  60,  77],\n",
              "         [ 44,  60,  77]],\n",
              "\n",
              "        [[ 84,  89, 120],\n",
              "         [ 86,  91, 121],\n",
              "         [ 89,  96, 123],\n",
              "         ...,\n",
              "         [ 30,  46,  63],\n",
              "         [ 38,  54,  71],\n",
              "         [ 35,  51,  69]],\n",
              "\n",
              "        [[ 90,  95, 126],\n",
              "         [ 87,  93, 122],\n",
              "         [ 84,  91, 118],\n",
              "         ...,\n",
              "         [ 37,  53,  70],\n",
              "         [ 32,  48,  65],\n",
              "         [ 30,  46,  63]]],\n",
              "\n",
              "\n",
              "       [[[ 94, 128, 127],\n",
              "         [ 97, 131, 130],\n",
              "         [ 96, 130, 129],\n",
              "         ...,\n",
              "         [ 14,  12,  22],\n",
              "         [ 18,  34,  17],\n",
              "         [ 84, 118, 112]],\n",
              "\n",
              "        [[ 95, 129, 128],\n",
              "         [ 96, 130, 129],\n",
              "         [ 96, 130, 129],\n",
              "         ...,\n",
              "         [  4,  12,  18],\n",
              "         [ 16,  11,  11],\n",
              "         [ 51,  69,  58]],\n",
              "\n",
              "        [[ 97, 130, 129],\n",
              "         [ 96, 130, 129],\n",
              "         [ 96, 130, 129],\n",
              "         ...,\n",
              "         [ 33,  31,  40],\n",
              "         [ 15,  21,  28],\n",
              "         [ 11,  18,  13]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 53,  70,  79],\n",
              "         [ 76, 102, 118],\n",
              "         [153, 194, 208],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              "\n",
              "        [[ 57,  75,  86],\n",
              "         [ 19,  36,  45],\n",
              "         [109, 143, 153],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              "\n",
              "        [[193, 194, 203],\n",
              "         [185, 218, 232],\n",
              "         [ 57, 115, 131],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]],\n",
              "\n",
              "\n",
              "       [[[ 55,  92, 118],\n",
              "         [ 42,  79, 105],\n",
              "         [ 55,  92, 118],\n",
              "         ...,\n",
              "         [219, 240, 249],\n",
              "         [229, 247, 251],\n",
              "         [241, 254, 255]],\n",
              "\n",
              "        [[ 39,  79, 104],\n",
              "         [ 26,  66,  91],\n",
              "         [ 40,  80, 105],\n",
              "         ...,\n",
              "         [202, 226, 237],\n",
              "         [220, 239, 246],\n",
              "         [239, 253, 255]],\n",
              "\n",
              "        [[ 24,  64,  89],\n",
              "         [ 30,  70,  95],\n",
              "         [ 48,  88, 113],\n",
              "         ...,\n",
              "         [188, 214, 226],\n",
              "         [219, 240, 248],\n",
              "         [237, 253, 255]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 28,  55,  74],\n",
              "         [ 27,  55,  72],\n",
              "         [ 45,  71,  88],\n",
              "         ...,\n",
              "         [ 26,  56,  89],\n",
              "         [ 11,  30,  51],\n",
              "         [  0,   6,  18]],\n",
              "\n",
              "        [[ 21,  47,  66],\n",
              "         [ 19,  45,  62],\n",
              "         [ 38,  64,  81],\n",
              "         ...,\n",
              "         [ 30,  58,  90],\n",
              "         [ 11,  28,  47],\n",
              "         [  1,   7,  18]],\n",
              "\n",
              "        [[ 19,  44,  63],\n",
              "         [ 11,  37,  54],\n",
              "         [ 35,  59,  77],\n",
              "         ...,\n",
              "         [ 27,  54,  83],\n",
              "         [  7,  21,  41],\n",
              "         [  2,   6,  17]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [ 18,  19,  23],\n",
              "         [ 16,  17,  21],\n",
              "         [ 40,  41,  45]],\n",
              "\n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [ 16,  17,  21],\n",
              "         [  8,   9,  13],\n",
              "         [ 16,  17,  21]],\n",
              "\n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [ 15,  16,  20],\n",
              "         [ 19,  20,  24],\n",
              "         [ 14,  15,  19]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[251, 205, 161],\n",
              "         [197, 105,  20],\n",
              "         [220, 114,   4],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[229, 164,  91],\n",
              "         [231, 143,  52],\n",
              "         [224, 138,  61],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[239, 168, 125],\n",
              "         [229, 161, 111],\n",
              "         [242, 189, 147],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]],\n",
              "\n",
              "\n",
              "       [[[ 58,  60,  74],\n",
              "         [ 55,  60,  72],\n",
              "         [ 54,  58,  71],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[ 56,  56,  68],\n",
              "         [ 54,  56,  67],\n",
              "         [ 55,  57,  67],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[ 45,  43,  53],\n",
              "         [ 45,  43,  53],\n",
              "         [ 40,  40,  49],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[251, 245, 253],\n",
              "         [249, 242, 252],\n",
              "         [208, 202, 214],\n",
              "         ...,\n",
              "         [208, 144, 100],\n",
              "         [198, 133,  89],\n",
              "         [187, 120,  75]],\n",
              "\n",
              "        [[253, 248, 253],\n",
              "         [254, 248, 255],\n",
              "         [252, 246, 252],\n",
              "         ...,\n",
              "         [200, 136,  92],\n",
              "         [201, 136,  91],\n",
              "         [191, 125,  79]],\n",
              "\n",
              "        [[254, 255, 250],\n",
              "         [252, 254, 248],\n",
              "         [253, 255, 250],\n",
              "         ...,\n",
              "         [164, 100,  60],\n",
              "         [193, 128,  85],\n",
              "         [186, 121,  76]]],\n",
              "\n",
              "\n",
              "       [[[ 23,  31,  59],\n",
              "         [ 20,  26,  51],\n",
              "         [ 21,  25,  49],\n",
              "         ...,\n",
              "         [108, 108, 131],\n",
              "         [181, 180, 196],\n",
              "         [244, 243, 253]],\n",
              "\n",
              "        [[ 16,  23,  53],\n",
              "         [ 14,  18,  46],\n",
              "         [ 18,  21,  45],\n",
              "         ...,\n",
              "         [ 90,  90, 113],\n",
              "         [173, 172, 188],\n",
              "         [239, 238, 246]],\n",
              "\n",
              "        [[ 24,  30,  62],\n",
              "         [ 26,  30,  59],\n",
              "         [ 21,  24,  51],\n",
              "         ...,\n",
              "         [103, 103, 127],\n",
              "         [148, 146, 165],\n",
              "         [222, 222, 232]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[255, 255, 252],\n",
              "         [255, 254, 251],\n",
              "         [243, 251, 252],\n",
              "         ...,\n",
              "         [235, 242, 254],\n",
              "         [243, 249, 255],\n",
              "         [248, 254, 255]],\n",
              "\n",
              "        [[255, 254, 246],\n",
              "         [255, 255, 251],\n",
              "         [241, 252, 255],\n",
              "         ...,\n",
              "         [153, 168, 215],\n",
              "         [182, 196, 232],\n",
              "         [218, 230, 252]],\n",
              "\n",
              "        [[254, 251, 253],\n",
              "         [252, 252, 255],\n",
              "         [226, 240, 255],\n",
              "         ...,\n",
              "         [114, 128, 190],\n",
              "         [127, 140, 193],\n",
              "         [149, 161, 203]]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkunorzO1u95",
        "outputId": "6eab69bc-ef57-4ed3-ebb0-0bc33c7c8394"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 3, ..., 1, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTP5BAR71v5e",
        "outputId": "f176a310-dee7-4f24-d690-e5ff3f4be8cf"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1657"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83MIIWMN2qhA",
        "outputId": "86c6e47c-9c6e-4033-f608-d7499ab7457b"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1657"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mrmcAmq3CIO",
        "outputId": "8c5a7cdb-a049-4c93-d306-26f101593ce3"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1657, 48, 48, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RX6k2wc3Hix",
        "outputId": "89802e7b-a5f5-421b-98fe-387e97cbc284"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1657,)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_X = X / 255.0"
      ],
      "metadata": {
        "id": "3jEWJ69J3LZ_"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_X"
      ],
      "metadata": {
        "id": "U_hProo43Y0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a74908-bcf5-4dd0-cd32-8c81302b0be9"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.11764706, 0.18039216, 0.23137255],\n",
              "         [0.12941176, 0.18431373, 0.23921569],\n",
              "         [0.15686275, 0.2       , 0.25490196],\n",
              "         ...,\n",
              "         [0.36078431, 0.39215686, 0.44705882],\n",
              "         [0.37647059, 0.40784314, 0.45882353],\n",
              "         [0.24313725, 0.27843137, 0.31764706]],\n",
              "\n",
              "        [[0.10980392, 0.16078431, 0.21568627],\n",
              "         [0.10588235, 0.14901961, 0.20392157],\n",
              "         [0.2       , 0.23921569, 0.29411765],\n",
              "         ...,\n",
              "         [0.34117647, 0.36862745, 0.43137255],\n",
              "         [0.35294118, 0.38039216, 0.43921569],\n",
              "         [0.39215686, 0.42352941, 0.4745098 ]],\n",
              "\n",
              "        [[0.13333333, 0.17647059, 0.23137255],\n",
              "         [0.11764706, 0.15686275, 0.21176471],\n",
              "         [0.25882353, 0.29411765, 0.34901961],\n",
              "         ...,\n",
              "         [0.34117647, 0.36862745, 0.43529412],\n",
              "         [0.37254902, 0.4       , 0.46666667],\n",
              "         [0.36470588, 0.39215686, 0.45098039]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.33333333, 0.35686275, 0.47843137],\n",
              "         [0.3372549 , 0.36078431, 0.47843137],\n",
              "         [0.3372549 , 0.36470588, 0.47058824],\n",
              "         ...,\n",
              "         [0.12156863, 0.18431373, 0.25098039],\n",
              "         [0.17254902, 0.23529412, 0.30196078],\n",
              "         [0.17254902, 0.23529412, 0.30196078]],\n",
              "\n",
              "        [[0.32941176, 0.34901961, 0.47058824],\n",
              "         [0.3372549 , 0.35686275, 0.4745098 ],\n",
              "         [0.34901961, 0.37647059, 0.48235294],\n",
              "         ...,\n",
              "         [0.11764706, 0.18039216, 0.24705882],\n",
              "         [0.14901961, 0.21176471, 0.27843137],\n",
              "         [0.1372549 , 0.2       , 0.27058824]],\n",
              "\n",
              "        [[0.35294118, 0.37254902, 0.49411765],\n",
              "         [0.34117647, 0.36470588, 0.47843137],\n",
              "         [0.32941176, 0.35686275, 0.4627451 ],\n",
              "         ...,\n",
              "         [0.14509804, 0.20784314, 0.2745098 ],\n",
              "         [0.1254902 , 0.18823529, 0.25490196],\n",
              "         [0.11764706, 0.18039216, 0.24705882]]],\n",
              "\n",
              "\n",
              "       [[[0.36862745, 0.50196078, 0.49803922],\n",
              "         [0.38039216, 0.51372549, 0.50980392],\n",
              "         [0.37647059, 0.50980392, 0.50588235],\n",
              "         ...,\n",
              "         [0.05490196, 0.04705882, 0.08627451],\n",
              "         [0.07058824, 0.13333333, 0.06666667],\n",
              "         [0.32941176, 0.4627451 , 0.43921569]],\n",
              "\n",
              "        [[0.37254902, 0.50588235, 0.50196078],\n",
              "         [0.37647059, 0.50980392, 0.50588235],\n",
              "         [0.37647059, 0.50980392, 0.50588235],\n",
              "         ...,\n",
              "         [0.01568627, 0.04705882, 0.07058824],\n",
              "         [0.0627451 , 0.04313725, 0.04313725],\n",
              "         [0.2       , 0.27058824, 0.22745098]],\n",
              "\n",
              "        [[0.38039216, 0.50980392, 0.50588235],\n",
              "         [0.37647059, 0.50980392, 0.50588235],\n",
              "         [0.37647059, 0.50980392, 0.50588235],\n",
              "         ...,\n",
              "         [0.12941176, 0.12156863, 0.15686275],\n",
              "         [0.05882353, 0.08235294, 0.10980392],\n",
              "         [0.04313725, 0.07058824, 0.05098039]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.20784314, 0.2745098 , 0.30980392],\n",
              "         [0.29803922, 0.4       , 0.4627451 ],\n",
              "         [0.6       , 0.76078431, 0.81568627],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ]],\n",
              "\n",
              "        [[0.22352941, 0.29411765, 0.3372549 ],\n",
              "         [0.0745098 , 0.14117647, 0.17647059],\n",
              "         [0.42745098, 0.56078431, 0.6       ],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ]],\n",
              "\n",
              "        [[0.75686275, 0.76078431, 0.79607843],\n",
              "         [0.7254902 , 0.85490196, 0.90980392],\n",
              "         [0.22352941, 0.45098039, 0.51372549],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ]]],\n",
              "\n",
              "\n",
              "       [[[0.21568627, 0.36078431, 0.4627451 ],\n",
              "         [0.16470588, 0.30980392, 0.41176471],\n",
              "         [0.21568627, 0.36078431, 0.4627451 ],\n",
              "         ...,\n",
              "         [0.85882353, 0.94117647, 0.97647059],\n",
              "         [0.89803922, 0.96862745, 0.98431373],\n",
              "         [0.94509804, 0.99607843, 1.        ]],\n",
              "\n",
              "        [[0.15294118, 0.30980392, 0.40784314],\n",
              "         [0.10196078, 0.25882353, 0.35686275],\n",
              "         [0.15686275, 0.31372549, 0.41176471],\n",
              "         ...,\n",
              "         [0.79215686, 0.88627451, 0.92941176],\n",
              "         [0.8627451 , 0.9372549 , 0.96470588],\n",
              "         [0.9372549 , 0.99215686, 1.        ]],\n",
              "\n",
              "        [[0.09411765, 0.25098039, 0.34901961],\n",
              "         [0.11764706, 0.2745098 , 0.37254902],\n",
              "         [0.18823529, 0.34509804, 0.44313725],\n",
              "         ...,\n",
              "         [0.7372549 , 0.83921569, 0.88627451],\n",
              "         [0.85882353, 0.94117647, 0.97254902],\n",
              "         [0.92941176, 0.99215686, 1.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.10980392, 0.21568627, 0.29019608],\n",
              "         [0.10588235, 0.21568627, 0.28235294],\n",
              "         [0.17647059, 0.27843137, 0.34509804],\n",
              "         ...,\n",
              "         [0.10196078, 0.21960784, 0.34901961],\n",
              "         [0.04313725, 0.11764706, 0.2       ],\n",
              "         [0.        , 0.02352941, 0.07058824]],\n",
              "\n",
              "        [[0.08235294, 0.18431373, 0.25882353],\n",
              "         [0.0745098 , 0.17647059, 0.24313725],\n",
              "         [0.14901961, 0.25098039, 0.31764706],\n",
              "         ...,\n",
              "         [0.11764706, 0.22745098, 0.35294118],\n",
              "         [0.04313725, 0.10980392, 0.18431373],\n",
              "         [0.00392157, 0.02745098, 0.07058824]],\n",
              "\n",
              "        [[0.0745098 , 0.17254902, 0.24705882],\n",
              "         [0.04313725, 0.14509804, 0.21176471],\n",
              "         [0.1372549 , 0.23137255, 0.30196078],\n",
              "         ...,\n",
              "         [0.10588235, 0.21176471, 0.3254902 ],\n",
              "         [0.02745098, 0.08235294, 0.16078431],\n",
              "         [0.00784314, 0.02352941, 0.06666667]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         ...,\n",
              "         [0.07058824, 0.0745098 , 0.09019608],\n",
              "         [0.0627451 , 0.06666667, 0.08235294],\n",
              "         [0.15686275, 0.16078431, 0.17647059]],\n",
              "\n",
              "        [[0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         ...,\n",
              "         [0.0627451 , 0.06666667, 0.08235294],\n",
              "         [0.03137255, 0.03529412, 0.05098039],\n",
              "         [0.0627451 , 0.06666667, 0.08235294]],\n",
              "\n",
              "        [[0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         ...,\n",
              "         [0.05882353, 0.0627451 , 0.07843137],\n",
              "         [0.0745098 , 0.07843137, 0.09411765],\n",
              "         [0.05490196, 0.05882353, 0.0745098 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.98431373, 0.80392157, 0.63137255],\n",
              "         [0.77254902, 0.41176471, 0.07843137],\n",
              "         [0.8627451 , 0.44705882, 0.01568627],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[0.89803922, 0.64313725, 0.35686275],\n",
              "         [0.90588235, 0.56078431, 0.20392157],\n",
              "         [0.87843137, 0.54117647, 0.23921569],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[0.9372549 , 0.65882353, 0.49019608],\n",
              "         [0.89803922, 0.63137255, 0.43529412],\n",
              "         [0.94901961, 0.74117647, 0.57647059],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]]],\n",
              "\n",
              "\n",
              "       [[[0.22745098, 0.23529412, 0.29019608],\n",
              "         [0.21568627, 0.23529412, 0.28235294],\n",
              "         [0.21176471, 0.22745098, 0.27843137],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[0.21960784, 0.21960784, 0.26666667],\n",
              "         [0.21176471, 0.21960784, 0.2627451 ],\n",
              "         [0.21568627, 0.22352941, 0.2627451 ],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[0.17647059, 0.16862745, 0.20784314],\n",
              "         [0.17647059, 0.16862745, 0.20784314],\n",
              "         [0.15686275, 0.15686275, 0.19215686],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.98431373, 0.96078431, 0.99215686],\n",
              "         [0.97647059, 0.94901961, 0.98823529],\n",
              "         [0.81568627, 0.79215686, 0.83921569],\n",
              "         ...,\n",
              "         [0.81568627, 0.56470588, 0.39215686],\n",
              "         [0.77647059, 0.52156863, 0.34901961],\n",
              "         [0.73333333, 0.47058824, 0.29411765]],\n",
              "\n",
              "        [[0.99215686, 0.97254902, 0.99215686],\n",
              "         [0.99607843, 0.97254902, 1.        ],\n",
              "         [0.98823529, 0.96470588, 0.98823529],\n",
              "         ...,\n",
              "         [0.78431373, 0.53333333, 0.36078431],\n",
              "         [0.78823529, 0.53333333, 0.35686275],\n",
              "         [0.74901961, 0.49019608, 0.30980392]],\n",
              "\n",
              "        [[0.99607843, 1.        , 0.98039216],\n",
              "         [0.98823529, 0.99607843, 0.97254902],\n",
              "         [0.99215686, 1.        , 0.98039216],\n",
              "         ...,\n",
              "         [0.64313725, 0.39215686, 0.23529412],\n",
              "         [0.75686275, 0.50196078, 0.33333333],\n",
              "         [0.72941176, 0.4745098 , 0.29803922]]],\n",
              "\n",
              "\n",
              "       [[[0.09019608, 0.12156863, 0.23137255],\n",
              "         [0.07843137, 0.10196078, 0.2       ],\n",
              "         [0.08235294, 0.09803922, 0.19215686],\n",
              "         ...,\n",
              "         [0.42352941, 0.42352941, 0.51372549],\n",
              "         [0.70980392, 0.70588235, 0.76862745],\n",
              "         [0.95686275, 0.95294118, 0.99215686]],\n",
              "\n",
              "        [[0.0627451 , 0.09019608, 0.20784314],\n",
              "         [0.05490196, 0.07058824, 0.18039216],\n",
              "         [0.07058824, 0.08235294, 0.17647059],\n",
              "         ...,\n",
              "         [0.35294118, 0.35294118, 0.44313725],\n",
              "         [0.67843137, 0.6745098 , 0.7372549 ],\n",
              "         [0.9372549 , 0.93333333, 0.96470588]],\n",
              "\n",
              "        [[0.09411765, 0.11764706, 0.24313725],\n",
              "         [0.10196078, 0.11764706, 0.23137255],\n",
              "         [0.08235294, 0.09411765, 0.2       ],\n",
              "         ...,\n",
              "         [0.40392157, 0.40392157, 0.49803922],\n",
              "         [0.58039216, 0.57254902, 0.64705882],\n",
              "         [0.87058824, 0.87058824, 0.90980392]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.        , 1.        , 0.98823529],\n",
              "         [1.        , 0.99607843, 0.98431373],\n",
              "         [0.95294118, 0.98431373, 0.98823529],\n",
              "         ...,\n",
              "         [0.92156863, 0.94901961, 0.99607843],\n",
              "         [0.95294118, 0.97647059, 1.        ],\n",
              "         [0.97254902, 0.99607843, 1.        ]],\n",
              "\n",
              "        [[1.        , 0.99607843, 0.96470588],\n",
              "         [1.        , 1.        , 0.98431373],\n",
              "         [0.94509804, 0.98823529, 1.        ],\n",
              "         ...,\n",
              "         [0.6       , 0.65882353, 0.84313725],\n",
              "         [0.71372549, 0.76862745, 0.90980392],\n",
              "         [0.85490196, 0.90196078, 0.98823529]],\n",
              "\n",
              "        [[0.99607843, 0.98431373, 0.99215686],\n",
              "         [0.98823529, 0.98823529, 1.        ],\n",
              "         [0.88627451, 0.94117647, 1.        ],\n",
              "         ...,\n",
              "         [0.44705882, 0.50196078, 0.74509804],\n",
              "         [0.49803922, 0.54901961, 0.75686275],\n",
              "         [0.58431373, 0.63137255, 0.79607843]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J09SQKhGPd4B",
        "outputId": "2b02a544-c413-4c24-9a33-31b0a7a575a7"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1657, 48, 48, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new=normalized_X.reshape((-1,48*48*3))\n",
        "X_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9t2a-10Pkho",
        "outputId": "04eea846-7d7d-4adc-936c-8ce925b0048d"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1657, 6912)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewcHhNi5QK0d",
        "outputId": "babde0cc-56f9-4d41-a623-88ed0f09a7d3"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11764706, 0.18039216, 0.23137255, ..., 0.11764706, 0.18039216,\n",
              "        0.24705882],\n",
              "       [0.36862745, 0.50196078, 0.49803922, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.21568627, 0.36078431, 0.4627451 , ..., 0.00784314, 0.02352941,\n",
              "        0.06666667],\n",
              "       ...,\n",
              "       [0.99607843, 0.99607843, 0.99607843, ..., 1.        , 1.        ,\n",
              "        1.        ],\n",
              "       [0.22745098, 0.23529412, 0.29019608, ..., 0.72941176, 0.4745098 ,\n",
              "        0.29803922],\n",
              "       [0.09019608, 0.12156863, 0.23137255, ..., 0.58431373, 0.63137255,\n",
              "        0.79607843]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J77-tRffQNqv",
        "outputId": "fa73e547-bdc5-4fde-839d-a25cfad140a9"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1657, 6912)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.Series(Y).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duakUIjVRxIE",
        "outputId": "d5d54946-6172-46bf-bc5f-dbc8b2438464"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    816\n",
              "6    529\n",
              "5    186\n",
              "1     57\n",
              "2     29\n",
              "4     26\n",
              "0     14\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKmtP1XhaXOJ",
        "outputId": "f0338a3c-dfe7-4c82-b0cc-9bb376afb202"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1692, 13068)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loJsmBCMagAF",
        "outputId": "16bdeeb6-e906-4842-ff30-a623bb2197d4"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1657,)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sampler = SMOTE()\n",
        "X_smote,Y_smote=sampler.fit_resample(X_new, Y)"
      ],
      "metadata": {
        "id": "h5GUz3h_UMwL"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(Y_smote).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqHIJ8F2VXsi",
        "outputId": "80e54500-9ba8-47a4-c133-2616e0ae81ba"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    816\n",
              "3    816\n",
              "6    816\n",
              "4    816\n",
              "0    816\n",
              "5    816\n",
              "2    816\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=X_smote.reshape(-1,48,48,3)"
      ],
      "metadata": {
        "id": "BxeQy6WRVnVn"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bym4wlL-WvUp",
        "outputId": "aacbf5a2-b42d-43dc-f10e-5060ed9179c3"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.11764706, 0.18039216, 0.23137255],\n",
              "         [0.12941176, 0.18431373, 0.23921569],\n",
              "         [0.15686275, 0.2       , 0.25490196],\n",
              "         ...,\n",
              "         [0.36078431, 0.39215686, 0.44705882],\n",
              "         [0.37647059, 0.40784314, 0.45882353],\n",
              "         [0.24313725, 0.27843137, 0.31764706]],\n",
              "\n",
              "        [[0.10980392, 0.16078431, 0.21568627],\n",
              "         [0.10588235, 0.14901961, 0.20392157],\n",
              "         [0.2       , 0.23921569, 0.29411765],\n",
              "         ...,\n",
              "         [0.34117647, 0.36862745, 0.43137255],\n",
              "         [0.35294118, 0.38039216, 0.43921569],\n",
              "         [0.39215686, 0.42352941, 0.4745098 ]],\n",
              "\n",
              "        [[0.13333333, 0.17647059, 0.23137255],\n",
              "         [0.11764706, 0.15686275, 0.21176471],\n",
              "         [0.25882353, 0.29411765, 0.34901961],\n",
              "         ...,\n",
              "         [0.34117647, 0.36862745, 0.43529412],\n",
              "         [0.37254902, 0.4       , 0.46666667],\n",
              "         [0.36470588, 0.39215686, 0.45098039]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.33333333, 0.35686275, 0.47843137],\n",
              "         [0.3372549 , 0.36078431, 0.47843137],\n",
              "         [0.3372549 , 0.36470588, 0.47058824],\n",
              "         ...,\n",
              "         [0.12156863, 0.18431373, 0.25098039],\n",
              "         [0.17254902, 0.23529412, 0.30196078],\n",
              "         [0.17254902, 0.23529412, 0.30196078]],\n",
              "\n",
              "        [[0.32941176, 0.34901961, 0.47058824],\n",
              "         [0.3372549 , 0.35686275, 0.4745098 ],\n",
              "         [0.34901961, 0.37647059, 0.48235294],\n",
              "         ...,\n",
              "         [0.11764706, 0.18039216, 0.24705882],\n",
              "         [0.14901961, 0.21176471, 0.27843137],\n",
              "         [0.1372549 , 0.2       , 0.27058824]],\n",
              "\n",
              "        [[0.35294118, 0.37254902, 0.49411765],\n",
              "         [0.34117647, 0.36470588, 0.47843137],\n",
              "         [0.32941176, 0.35686275, 0.4627451 ],\n",
              "         ...,\n",
              "         [0.14509804, 0.20784314, 0.2745098 ],\n",
              "         [0.1254902 , 0.18823529, 0.25490196],\n",
              "         [0.11764706, 0.18039216, 0.24705882]]],\n",
              "\n",
              "\n",
              "       [[[0.36862745, 0.50196078, 0.49803922],\n",
              "         [0.38039216, 0.51372549, 0.50980392],\n",
              "         [0.37647059, 0.50980392, 0.50588235],\n",
              "         ...,\n",
              "         [0.05490196, 0.04705882, 0.08627451],\n",
              "         [0.07058824, 0.13333333, 0.06666667],\n",
              "         [0.32941176, 0.4627451 , 0.43921569]],\n",
              "\n",
              "        [[0.37254902, 0.50588235, 0.50196078],\n",
              "         [0.37647059, 0.50980392, 0.50588235],\n",
              "         [0.37647059, 0.50980392, 0.50588235],\n",
              "         ...,\n",
              "         [0.01568627, 0.04705882, 0.07058824],\n",
              "         [0.0627451 , 0.04313725, 0.04313725],\n",
              "         [0.2       , 0.27058824, 0.22745098]],\n",
              "\n",
              "        [[0.38039216, 0.50980392, 0.50588235],\n",
              "         [0.37647059, 0.50980392, 0.50588235],\n",
              "         [0.37647059, 0.50980392, 0.50588235],\n",
              "         ...,\n",
              "         [0.12941176, 0.12156863, 0.15686275],\n",
              "         [0.05882353, 0.08235294, 0.10980392],\n",
              "         [0.04313725, 0.07058824, 0.05098039]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.20784314, 0.2745098 , 0.30980392],\n",
              "         [0.29803922, 0.4       , 0.4627451 ],\n",
              "         [0.6       , 0.76078431, 0.81568627],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ]],\n",
              "\n",
              "        [[0.22352941, 0.29411765, 0.3372549 ],\n",
              "         [0.0745098 , 0.14117647, 0.17647059],\n",
              "         [0.42745098, 0.56078431, 0.6       ],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ]],\n",
              "\n",
              "        [[0.75686275, 0.76078431, 0.79607843],\n",
              "         [0.7254902 , 0.85490196, 0.90980392],\n",
              "         [0.22352941, 0.45098039, 0.51372549],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ]]],\n",
              "\n",
              "\n",
              "       [[[0.21568627, 0.36078431, 0.4627451 ],\n",
              "         [0.16470588, 0.30980392, 0.41176471],\n",
              "         [0.21568627, 0.36078431, 0.4627451 ],\n",
              "         ...,\n",
              "         [0.85882353, 0.94117647, 0.97647059],\n",
              "         [0.89803922, 0.96862745, 0.98431373],\n",
              "         [0.94509804, 0.99607843, 1.        ]],\n",
              "\n",
              "        [[0.15294118, 0.30980392, 0.40784314],\n",
              "         [0.10196078, 0.25882353, 0.35686275],\n",
              "         [0.15686275, 0.31372549, 0.41176471],\n",
              "         ...,\n",
              "         [0.79215686, 0.88627451, 0.92941176],\n",
              "         [0.8627451 , 0.9372549 , 0.96470588],\n",
              "         [0.9372549 , 0.99215686, 1.        ]],\n",
              "\n",
              "        [[0.09411765, 0.25098039, 0.34901961],\n",
              "         [0.11764706, 0.2745098 , 0.37254902],\n",
              "         [0.18823529, 0.34509804, 0.44313725],\n",
              "         ...,\n",
              "         [0.7372549 , 0.83921569, 0.88627451],\n",
              "         [0.85882353, 0.94117647, 0.97254902],\n",
              "         [0.92941176, 0.99215686, 1.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.10980392, 0.21568627, 0.29019608],\n",
              "         [0.10588235, 0.21568627, 0.28235294],\n",
              "         [0.17647059, 0.27843137, 0.34509804],\n",
              "         ...,\n",
              "         [0.10196078, 0.21960784, 0.34901961],\n",
              "         [0.04313725, 0.11764706, 0.2       ],\n",
              "         [0.        , 0.02352941, 0.07058824]],\n",
              "\n",
              "        [[0.08235294, 0.18431373, 0.25882353],\n",
              "         [0.0745098 , 0.17647059, 0.24313725],\n",
              "         [0.14901961, 0.25098039, 0.31764706],\n",
              "         ...,\n",
              "         [0.11764706, 0.22745098, 0.35294118],\n",
              "         [0.04313725, 0.10980392, 0.18431373],\n",
              "         [0.00392157, 0.02745098, 0.07058824]],\n",
              "\n",
              "        [[0.0745098 , 0.17254902, 0.24705882],\n",
              "         [0.04313725, 0.14509804, 0.21176471],\n",
              "         [0.1372549 , 0.23137255, 0.30196078],\n",
              "         ...,\n",
              "         [0.10588235, 0.21176471, 0.3254902 ],\n",
              "         [0.02745098, 0.08235294, 0.16078431],\n",
              "         [0.00784314, 0.02352941, 0.06666667]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.99957692, 0.99959615, 0.99568419],\n",
              "         [0.99175301, 0.99568419, 0.98786029],\n",
              "         [0.96045738, 0.96438857, 0.95656466],\n",
              "         ...,\n",
              "         [0.96039969, 0.95648774, 0.97213555],\n",
              "         [0.99952884, 0.99561688, 0.99952884],\n",
              "         [0.9486446 , 0.94473265, 0.95255655]],\n",
              "\n",
              "        [[0.99566496, 0.99959615, 0.98394833],\n",
              "         [0.94480957, 0.94874076, 0.93309294],\n",
              "         [0.99955768, 0.99957692, 0.99566496],\n",
              "         ...,\n",
              "         [0.96430203, 0.96039008, 0.97603789],\n",
              "         [0.99950961, 0.99559765, 0.99950961],\n",
              "         [0.99950961, 0.99559765, 0.99950961]],\n",
              "\n",
              "        [[0.98001715, 0.98394833, 0.96830052],\n",
              "         [0.99175301, 0.99568419, 0.98003638],\n",
              "         [0.96437895, 0.96831014, 0.96048623],\n",
              "         ...,\n",
              "         [0.99559765, 0.9916857 , 0.99950961],\n",
              "         [0.94865422, 0.94474226, 0.96039008],\n",
              "         [0.91344664, 0.90953469, 0.91735859]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.08816878, 0.08433375, 0.11962787],\n",
              "         [0.06294702, 0.05910238, 0.09441573],\n",
              "         [0.0280183 , 0.02810484, 0.05165348],\n",
              "         ...,\n",
              "         [0.99953845, 0.99953845, 0.99953845],\n",
              "         [0.99950961, 0.99950961, 0.99950961],\n",
              "         [0.99952884, 0.99952884, 0.99952884]],\n",
              "\n",
              "        [[0.08655336, 0.09449265, 0.12588443],\n",
              "         [0.11923363, 0.12717292, 0.1585647 ],\n",
              "         [0.05925623, 0.05937162, 0.08293949],\n",
              "         ...,\n",
              "         [0.99952884, 0.99952884, 0.99952884],\n",
              "         [0.99951922, 0.99951922, 0.99951922],\n",
              "         [0.99952884, 0.99952884, 0.99952884]],\n",
              "\n",
              "        [[0.06817631, 0.0643509 , 0.09958732],\n",
              "         [0.15828585, 0.15447005, 0.18967763],\n",
              "         [0.078941  , 0.07119402, 0.09473304],\n",
              "         ...,\n",
              "         [0.99952884, 0.99952884, 0.99952884],\n",
              "         [0.99951922, 0.99951922, 0.99951922],\n",
              "         [0.99952884, 0.99952884, 0.99952884]]],\n",
              "\n",
              "\n",
              "       [[[0.36194989, 0.37086502, 0.38511287],\n",
              "         [0.31567849, 0.34239662, 0.35094532],\n",
              "         [0.23732897, 0.27152381, 0.29147079],\n",
              "         ...,\n",
              "         [0.21587727, 0.28463337, 0.34086461],\n",
              "         [0.28562351, 0.32980548, 0.35788017],\n",
              "         [0.36140803, 0.39526372, 0.40694657]],\n",
              "\n",
              "        [[0.3473629 , 0.3580556 , 0.37444745],\n",
              "         [0.29965307, 0.3274432 , 0.3370639 ],\n",
              "         [0.22736912, 0.26548553, 0.28935408],\n",
              "         ...,\n",
              "         [0.22941955, 0.28677736, 0.34834132],\n",
              "         [0.20044828, 0.25602853, 0.30405021],\n",
              "         [0.29008694, 0.33249134, 0.35842203]],\n",
              "\n",
              "        [[0.33599191, 0.34561261, 0.36414846],\n",
              "         [0.25087125, 0.28436051, 0.29790279],\n",
              "         [0.18640315, 0.22559155, 0.25338168],\n",
              "         ...,\n",
              "         [0.1637976 , 0.21937784, 0.28520251],\n",
              "         [0.16797645, 0.22855026, 0.28368223],\n",
              "         [0.20747671, 0.25665225, 0.28328851]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.06240596, 0.08703465, 0.10018321],\n",
              "         [0.17037774, 0.20747671, 0.22454684],\n",
              "         [0.17647059, 0.2181967 , 0.25628582],\n",
              "         ...,\n",
              "         [0.35287489, 0.41734298, 0.5241882 ],\n",
              "         [0.41282499, 0.48476979, 0.5766343 ],\n",
              "         [0.37535959, 0.43697811, 0.5145402 ]],\n",
              "\n",
              "        [[0.13045648, 0.15722917, 0.17037774],\n",
              "         [0.13477176, 0.17079873, 0.19001286],\n",
              "         [0.14972518, 0.19430086, 0.23275641],\n",
              "         ...,\n",
              "         [0.3614236 , 0.42481969, 0.52988733],\n",
              "         [0.40997542, 0.48192022, 0.57485673],\n",
              "         [0.34931975, 0.41093827, 0.48957236]],\n",
              "\n",
              "        [[0.24344911, 0.26914981, 0.28658637],\n",
              "         [0.18894087, 0.22603984, 0.24846997],\n",
              "         [0.20350057, 0.24700425, 0.2876038 ],\n",
              "         ...,\n",
              "         [0.3614236 , 0.4333684 , 0.53665847],\n",
              "         [0.41530813, 0.48618094, 0.58018944],\n",
              "         [0.32787976, 0.38842629, 0.47027638]]],\n",
              "\n",
              "\n",
              "       [[[0.21945752, 0.25501872, 0.28969548],\n",
              "         [0.20692514, 0.24463904, 0.28020024],\n",
              "         [0.17274897, 0.2113473 , 0.25121391],\n",
              "         ...,\n",
              "         [0.13969074, 0.16133453, 0.17905675],\n",
              "         [0.09616965, 0.09351635, 0.10820144],\n",
              "         [0.10785117, 0.10911944, 0.12038355]],\n",
              "\n",
              "        [[0.10896911, 0.14060874, 0.17920708],\n",
              "         [0.17755497, 0.21526887, 0.26297861],\n",
              "         [0.25271569, 0.2973883 , 0.34332917],\n",
              "         ...,\n",
              "         [0.23676234, 0.27055467, 0.29131403],\n",
              "         [0.18082562, 0.20854368, 0.22930304],\n",
              "         [0.16071718, 0.16502259, 0.1762867 ]],\n",
              "\n",
              "        [[0.15679561, 0.19450951, 0.23614498],\n",
              "         [0.09997446, 0.12250268, 0.16932799],\n",
              "         [0.20550654, 0.25321629, 0.3021943 ],\n",
              "         ...,\n",
              "         [0.30768478, 0.34451425, 0.36831075],\n",
              "         [0.26321213, 0.30307873, 0.32383809],\n",
              "         [0.17590286, 0.19539395, 0.20969519]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.40492276, 0.45566964, 0.54324598],\n",
              "         [0.32350387, 0.39247357, 0.47701278],\n",
              "         [0.09304932, 0.17024599, 0.26174391],\n",
              "         ...,\n",
              "         [0.0250312 , 0.01845633, 0.0170713 ],\n",
              "         [0.01591979, 0.01238206, 0.02921985],\n",
              "         [0.02945336, 0.04717558, 0.0983063 ]],\n",
              "\n",
              "        [[0.29346673, 0.33206506, 0.39230719],\n",
              "         [0.24914439, 0.27559418, 0.33583631],\n",
              "         [0.06951991, 0.08382116, 0.14406328],\n",
              "         ...,\n",
              "         [0.0250312 , 0.02756774, 0.02314557],\n",
              "         [0.0250312 , 0.03667915, 0.05655407],\n",
              "         [0.21333362, 0.2592745 , 0.31040522]],\n",
              "\n",
              "        [[0.05925699, 0.06444683, 0.08824332],\n",
              "         [0.08190197, 0.06583186, 0.08962835],\n",
              "         [0.07851456, 0.04422164, 0.07105526],\n",
              "         ...,\n",
              "         [0.0341426 , 0.03060487, 0.02921985],\n",
              "         [0.0250312 , 0.02756774, 0.03833125],\n",
              "         [0.14474777, 0.17461853, 0.21448514]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "onehot_encoded_y = to_categorical(Y)\n",
        "\n",
        "# Display the one-hot encoded representation\n",
        "print(onehot_encoded_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJp34gW83bMO",
        "outputId": "6d2702d2-9770-4e10-9e3f-b6a2b01b4264"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'x' is your input features and 'y' is the corresponding target labels\n",
        "# Replace these with your actual data arrays\n",
        "\n",
        "# Split the data into training (70%), testing (15%), and validation (15%) sets\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(normalized_X, onehot_encoded_y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Display the sizes of each split\n",
        "print(\"Training set size:\", len(X_train))\n",
        "print(\"Validation set size:\", len(X_val))\n",
        "print(\"Testing set size:\", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmY9hZKN9Skb",
        "outputId": "61ed8fab-4498-4303-fe24-bb11dbdfecd1"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 1159\n",
            "Validation set size: 249\n",
            "Testing set size: 249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Assuming 'x_train' is your training data and 'y_train' are the corresponding labels\n",
        "# Replace these with your actual training data and labels\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,      # Random rotation\n",
        "    width_shift_range=0.2,  # Random horizontal shift\n",
        "    height_shift_range=0.2, # Random vertical shift\n",
        "    shear_range=0.2,        # Random shear\n",
        "    zoom_range=0.2,         # Random zoom\n",
        "    horizontal_flip=True,   # Random horizontal flip\n",
        "    fill_mode='nearest'     # Fill mode for newly created pixels\n",
        ")\n",
        "\n",
        "# Fit the ImageDataGenerator on the training data\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Generate augmented data batches\n",
        "augmented_data_generator = datagen.flow(X_train, Y_train, batch_size=32)\n",
        "\n"
      ],
      "metadata": {
        "id": "l5-VGBImAQpR"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_o6oKKNCgOA",
        "outputId": "ca0cb95a-94b7-4525-b5f4-349fe651de5e"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8011008"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Y_train.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5LkK5BTJ118",
        "outputId": "f96a8cc6-9759-43c6-b866-4c5670ebec32"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8113"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "\n",
        "\n",
        "num_classes = 7\n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "history = model.fit(X_train, Y_train, batch_size=32, epochs=10, validation_data=(X_val, Y_val))\n",
        "\n",
        "\n",
        "val_loss, val_accuracy = model.evaluate(X_val, Y_val)\n",
        "\n",
        "print(\"Validation Accuracy:\", val_accuracy)"
      ],
      "metadata": {
        "id": "TJv0OJqPFIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ecf16d8-f9ea-4bf5-9d3a-935ba56d7c95"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_3   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,847,815\n",
            "Trainable params: 133,127\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "37/37 [==============================] - 4s 49ms/step - loss: 1.3030 - accuracy: 0.5047 - val_loss: 1.1380 - val_accuracy: 0.5622\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 1.0757 - accuracy: 0.5841 - val_loss: 1.0929 - val_accuracy: 0.5582\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.9907 - accuracy: 0.6186 - val_loss: 1.1027 - val_accuracy: 0.5542\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 0.9555 - accuracy: 0.6376 - val_loss: 1.0627 - val_accuracy: 0.5743\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 0.8616 - accuracy: 0.6859 - val_loss: 1.0807 - val_accuracy: 0.5863\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 0.8315 - accuracy: 0.6920 - val_loss: 1.1126 - val_accuracy: 0.5502\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 0.7750 - accuracy: 0.7118 - val_loss: 1.0490 - val_accuracy: 0.5944\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 0.7074 - accuracy: 0.7567 - val_loss: 1.0683 - val_accuracy: 0.5783\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 0.6506 - accuracy: 0.7834 - val_loss: 1.0693 - val_accuracy: 0.5622\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.6243 - accuracy: 0.7817 - val_loss: 1.0782 - val_accuracy: 0.5944\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0782 - accuracy: 0.5944\n",
            "Validation Accuracy: 0.5943775177001953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Assuming 'x_train' and 'y_train' are your training data and labels, respectively\n",
        "# Replace these with your actual training data and labels\n",
        "\n",
        "# Create the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first convolutional layer\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48,48,3)))\n",
        "\n",
        "# Add the first max-pooling layer\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Add the second convolutional layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Add the second max-pooling layer\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the output from the previous layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add the first fully connected (dense) layer\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add the output layer with appropriate number of classes and activation function\n",
        "num_classes = 7\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, epochs=200, batch_size=32, validation_data=(X_val, Y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5l3GNDzFu21",
        "outputId": "9ae37131-bd1c-4ea7-ecf0-931c4a861162"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "37/37 [==============================] - 2s 19ms/step - loss: 1.3234 - accuracy: 0.4789 - val_loss: 1.2135 - val_accuracy: 0.4940\n",
            "Epoch 2/200\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1.2245 - accuracy: 0.5280 - val_loss: 1.2252 - val_accuracy: 0.4779\n",
            "Epoch 3/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.1594 - accuracy: 0.5315 - val_loss: 1.1597 - val_accuracy: 0.5100\n",
            "Epoch 4/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.0529 - accuracy: 0.6031 - val_loss: 1.1850 - val_accuracy: 0.4900\n",
            "Epoch 5/200\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 0.9785 - accuracy: 0.6299 - val_loss: 1.0470 - val_accuracy: 0.5703\n",
            "Epoch 6/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 0.8952 - accuracy: 0.6730 - val_loss: 1.0882 - val_accuracy: 0.6145\n",
            "Epoch 7/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.8320 - accuracy: 0.6997 - val_loss: 1.0524 - val_accuracy: 0.6265\n",
            "Epoch 8/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.7198 - accuracy: 0.7420 - val_loss: 1.0671 - val_accuracy: 0.5823\n",
            "Epoch 9/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.6487 - accuracy: 0.7619 - val_loss: 1.0731 - val_accuracy: 0.6546\n",
            "Epoch 10/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 0.5585 - accuracy: 0.8067 - val_loss: 1.1574 - val_accuracy: 0.6265\n",
            "Epoch 11/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.4395 - accuracy: 0.8438 - val_loss: 1.1570 - val_accuracy: 0.6305\n",
            "Epoch 12/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.3303 - accuracy: 0.8878 - val_loss: 1.3109 - val_accuracy: 0.6345\n",
            "Epoch 13/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.2393 - accuracy: 0.9284 - val_loss: 1.4396 - val_accuracy: 0.6145\n",
            "Epoch 14/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 0.1966 - accuracy: 0.9439 - val_loss: 1.5944 - val_accuracy: 0.6305\n",
            "Epoch 15/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.1439 - accuracy: 0.9629 - val_loss: 1.4804 - val_accuracy: 0.6426\n",
            "Epoch 16/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0956 - accuracy: 0.9767 - val_loss: 1.4947 - val_accuracy: 0.6265\n",
            "Epoch 17/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0653 - accuracy: 0.9879 - val_loss: 1.6434 - val_accuracy: 0.6345\n",
            "Epoch 18/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0415 - accuracy: 0.9957 - val_loss: 1.7809 - val_accuracy: 0.6586\n",
            "Epoch 19/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9991 - val_loss: 1.9240 - val_accuracy: 0.6667\n",
            "Epoch 20/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.0161 - val_accuracy: 0.6667\n",
            "Epoch 21/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.0317 - val_accuracy: 0.6426\n",
            "Epoch 22/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.1117 - val_accuracy: 0.6466\n",
            "Epoch 23/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.1288 - val_accuracy: 0.6386\n",
            "Epoch 24/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.2168 - val_accuracy: 0.6466\n",
            "Epoch 25/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.2658 - val_accuracy: 0.6506\n",
            "Epoch 26/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.3659 - val_accuracy: 0.6546\n",
            "Epoch 27/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3933 - val_accuracy: 0.6546\n",
            "Epoch 28/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.3394 - val_accuracy: 0.6386\n",
            "Epoch 29/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3591 - val_accuracy: 0.6386\n",
            "Epoch 30/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3908 - val_accuracy: 0.6506\n",
            "Epoch 31/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4461 - val_accuracy: 0.6506\n",
            "Epoch 32/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4909 - val_accuracy: 0.6466\n",
            "Epoch 33/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.4596 - val_accuracy: 0.6426\n",
            "Epoch 34/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5067 - val_accuracy: 0.6466\n",
            "Epoch 35/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5505 - val_accuracy: 0.6426\n",
            "Epoch 36/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5584 - val_accuracy: 0.6426\n",
            "Epoch 37/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.5865 - val_accuracy: 0.6386\n",
            "Epoch 38/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.5982 - val_accuracy: 0.6426\n",
            "Epoch 39/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6210 - val_accuracy: 0.6386\n",
            "Epoch 40/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6390 - val_accuracy: 0.6466\n",
            "Epoch 41/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 9.5694e-04 - accuracy: 1.0000 - val_loss: 2.6117 - val_accuracy: 0.6426\n",
            "Epoch 42/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 8.7672e-04 - accuracy: 1.0000 - val_loss: 2.6727 - val_accuracy: 0.6345\n",
            "Epoch 43/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 8.1900e-04 - accuracy: 1.0000 - val_loss: 2.6928 - val_accuracy: 0.6305\n",
            "Epoch 44/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 7.6932e-04 - accuracy: 1.0000 - val_loss: 2.7092 - val_accuracy: 0.6305\n",
            "Epoch 45/200\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 7.3668e-04 - accuracy: 1.0000 - val_loss: 2.7108 - val_accuracy: 0.6305\n",
            "Epoch 46/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.9899e-04 - accuracy: 1.0000 - val_loss: 2.7238 - val_accuracy: 0.6345\n",
            "Epoch 47/200\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 6.4998e-04 - accuracy: 1.0000 - val_loss: 2.7282 - val_accuracy: 0.6345\n",
            "Epoch 48/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.1942e-04 - accuracy: 1.0000 - val_loss: 2.7641 - val_accuracy: 0.6305\n",
            "Epoch 49/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.8257e-04 - accuracy: 1.0000 - val_loss: 2.7632 - val_accuracy: 0.6345\n",
            "Epoch 50/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 5.5012e-04 - accuracy: 1.0000 - val_loss: 2.7848 - val_accuracy: 0.6386\n",
            "Epoch 51/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.2379e-04 - accuracy: 1.0000 - val_loss: 2.8083 - val_accuracy: 0.6305\n",
            "Epoch 52/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 4.9589e-04 - accuracy: 1.0000 - val_loss: 2.8150 - val_accuracy: 0.6345\n",
            "Epoch 53/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.7166e-04 - accuracy: 1.0000 - val_loss: 2.8293 - val_accuracy: 0.6305\n",
            "Epoch 54/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 4.4873e-04 - accuracy: 1.0000 - val_loss: 2.8414 - val_accuracy: 0.6305\n",
            "Epoch 55/200\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 4.2782e-04 - accuracy: 1.0000 - val_loss: 2.8545 - val_accuracy: 0.6305\n",
            "Epoch 56/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.0921e-04 - accuracy: 1.0000 - val_loss: 2.8600 - val_accuracy: 0.6265\n",
            "Epoch 57/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.9164e-04 - accuracy: 1.0000 - val_loss: 2.8832 - val_accuracy: 0.6265\n",
            "Epoch 58/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.7488e-04 - accuracy: 1.0000 - val_loss: 2.8801 - val_accuracy: 0.6265\n",
            "Epoch 59/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.5793e-04 - accuracy: 1.0000 - val_loss: 2.8992 - val_accuracy: 0.6305\n",
            "Epoch 60/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.4305e-04 - accuracy: 1.0000 - val_loss: 2.9176 - val_accuracy: 0.6305\n",
            "Epoch 61/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.3371e-04 - accuracy: 1.0000 - val_loss: 2.9059 - val_accuracy: 0.6305\n",
            "Epoch 62/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.1634e-04 - accuracy: 1.0000 - val_loss: 2.9338 - val_accuracy: 0.6265\n",
            "Epoch 63/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.9919e-04 - accuracy: 1.0000 - val_loss: 2.9670 - val_accuracy: 0.6305\n",
            "Epoch 64/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.8807e-04 - accuracy: 1.0000 - val_loss: 2.9596 - val_accuracy: 0.6265\n",
            "Epoch 65/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.7928e-04 - accuracy: 1.0000 - val_loss: 2.9729 - val_accuracy: 0.6265\n",
            "Epoch 66/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6783e-04 - accuracy: 1.0000 - val_loss: 2.9921 - val_accuracy: 0.6305\n",
            "Epoch 67/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.5596e-04 - accuracy: 1.0000 - val_loss: 3.0021 - val_accuracy: 0.6305\n",
            "Epoch 68/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.4633e-04 - accuracy: 1.0000 - val_loss: 3.0300 - val_accuracy: 0.6305\n",
            "Epoch 69/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.3607e-04 - accuracy: 1.0000 - val_loss: 3.0285 - val_accuracy: 0.6305\n",
            "Epoch 70/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.2759e-04 - accuracy: 1.0000 - val_loss: 3.0199 - val_accuracy: 0.6265\n",
            "Epoch 71/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.1836e-04 - accuracy: 1.0000 - val_loss: 3.0462 - val_accuracy: 0.6265\n",
            "Epoch 72/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.0912e-04 - accuracy: 1.0000 - val_loss: 3.0446 - val_accuracy: 0.6305\n",
            "Epoch 73/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.0289e-04 - accuracy: 1.0000 - val_loss: 3.0550 - val_accuracy: 0.6305\n",
            "Epoch 74/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.9720e-04 - accuracy: 1.0000 - val_loss: 3.0774 - val_accuracy: 0.6265\n",
            "Epoch 75/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.8734e-04 - accuracy: 1.0000 - val_loss: 3.0854 - val_accuracy: 0.6305\n",
            "Epoch 76/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.8187e-04 - accuracy: 1.0000 - val_loss: 3.0983 - val_accuracy: 0.6265\n",
            "Epoch 77/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.7483e-04 - accuracy: 1.0000 - val_loss: 3.1137 - val_accuracy: 0.6305\n",
            "Epoch 78/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.6987e-04 - accuracy: 1.0000 - val_loss: 3.1016 - val_accuracy: 0.6265\n",
            "Epoch 79/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.6453e-04 - accuracy: 1.0000 - val_loss: 3.1243 - val_accuracy: 0.6265\n",
            "Epoch 80/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.5753e-04 - accuracy: 1.0000 - val_loss: 3.1283 - val_accuracy: 0.6305\n",
            "Epoch 81/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.5242e-04 - accuracy: 1.0000 - val_loss: 3.1355 - val_accuracy: 0.6265\n",
            "Epoch 82/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.4854e-04 - accuracy: 1.0000 - val_loss: 3.1356 - val_accuracy: 0.6265\n",
            "Epoch 83/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.4418e-04 - accuracy: 1.0000 - val_loss: 3.1553 - val_accuracy: 0.6265\n",
            "Epoch 84/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.3854e-04 - accuracy: 1.0000 - val_loss: 3.1524 - val_accuracy: 0.6305\n",
            "Epoch 85/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.3397e-04 - accuracy: 1.0000 - val_loss: 3.1635 - val_accuracy: 0.6305\n",
            "Epoch 86/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.3040e-04 - accuracy: 1.0000 - val_loss: 3.1719 - val_accuracy: 0.6345\n",
            "Epoch 87/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.2508e-04 - accuracy: 1.0000 - val_loss: 3.1887 - val_accuracy: 0.6305\n",
            "Epoch 88/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.2045e-04 - accuracy: 1.0000 - val_loss: 3.2048 - val_accuracy: 0.6265\n",
            "Epoch 89/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.1666e-04 - accuracy: 1.0000 - val_loss: 3.2150 - val_accuracy: 0.6265\n",
            "Epoch 90/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.1301e-04 - accuracy: 1.0000 - val_loss: 3.2276 - val_accuracy: 0.6305\n",
            "Epoch 91/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.0949e-04 - accuracy: 1.0000 - val_loss: 3.2308 - val_accuracy: 0.6265\n",
            "Epoch 92/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.0735e-04 - accuracy: 1.0000 - val_loss: 3.2315 - val_accuracy: 0.6345\n",
            "Epoch 93/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.0253e-04 - accuracy: 1.0000 - val_loss: 3.2401 - val_accuracy: 0.6345\n",
            "Epoch 94/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.0023e-04 - accuracy: 1.0000 - val_loss: 3.2545 - val_accuracy: 0.6265\n",
            "Epoch 95/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 9.6398e-05 - accuracy: 1.0000 - val_loss: 3.2641 - val_accuracy: 0.6305\n",
            "Epoch 96/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 9.4016e-05 - accuracy: 1.0000 - val_loss: 3.2488 - val_accuracy: 0.6345\n",
            "Epoch 97/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 9.1109e-05 - accuracy: 1.0000 - val_loss: 3.2723 - val_accuracy: 0.6305\n",
            "Epoch 98/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 8.8283e-05 - accuracy: 1.0000 - val_loss: 3.2924 - val_accuracy: 0.6265\n",
            "Epoch 99/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 8.6077e-05 - accuracy: 1.0000 - val_loss: 3.3030 - val_accuracy: 0.6305\n",
            "Epoch 100/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 8.4022e-05 - accuracy: 1.0000 - val_loss: 3.2953 - val_accuracy: 0.6345\n",
            "Epoch 101/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.0844e-05 - accuracy: 1.0000 - val_loss: 3.2990 - val_accuracy: 0.6305\n",
            "Epoch 102/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 7.8059e-05 - accuracy: 1.0000 - val_loss: 3.3269 - val_accuracy: 0.6265\n",
            "Epoch 103/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 7.5563e-05 - accuracy: 1.0000 - val_loss: 3.3300 - val_accuracy: 0.6265\n",
            "Epoch 104/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 7.3673e-05 - accuracy: 1.0000 - val_loss: 3.3403 - val_accuracy: 0.6265\n",
            "Epoch 105/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.1517e-05 - accuracy: 1.0000 - val_loss: 3.3555 - val_accuracy: 0.6305\n",
            "Epoch 106/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.9391e-05 - accuracy: 1.0000 - val_loss: 3.3459 - val_accuracy: 0.6345\n",
            "Epoch 107/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.7556e-05 - accuracy: 1.0000 - val_loss: 3.3633 - val_accuracy: 0.6265\n",
            "Epoch 108/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.6409e-05 - accuracy: 1.0000 - val_loss: 3.3674 - val_accuracy: 0.6305\n",
            "Epoch 109/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.4332e-05 - accuracy: 1.0000 - val_loss: 3.3724 - val_accuracy: 0.6345\n",
            "Epoch 110/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.1823e-05 - accuracy: 1.0000 - val_loss: 3.3859 - val_accuracy: 0.6265\n",
            "Epoch 111/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.0503e-05 - accuracy: 1.0000 - val_loss: 3.3810 - val_accuracy: 0.6305\n",
            "Epoch 112/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 5.8361e-05 - accuracy: 1.0000 - val_loss: 3.4086 - val_accuracy: 0.6265\n",
            "Epoch 113/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.7016e-05 - accuracy: 1.0000 - val_loss: 3.4116 - val_accuracy: 0.6305\n",
            "Epoch 114/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.5253e-05 - accuracy: 1.0000 - val_loss: 3.4144 - val_accuracy: 0.6305\n",
            "Epoch 115/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.3483e-05 - accuracy: 1.0000 - val_loss: 3.4235 - val_accuracy: 0.6305\n",
            "Epoch 116/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 5.2090e-05 - accuracy: 1.0000 - val_loss: 3.4419 - val_accuracy: 0.6305\n",
            "Epoch 117/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.1236e-05 - accuracy: 1.0000 - val_loss: 3.4436 - val_accuracy: 0.6265\n",
            "Epoch 118/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.0094e-05 - accuracy: 1.0000 - val_loss: 3.4397 - val_accuracy: 0.6305\n",
            "Epoch 119/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.7973e-05 - accuracy: 1.0000 - val_loss: 3.4603 - val_accuracy: 0.6305\n",
            "Epoch 120/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.7044e-05 - accuracy: 1.0000 - val_loss: 3.4564 - val_accuracy: 0.6305\n",
            "Epoch 121/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.5737e-05 - accuracy: 1.0000 - val_loss: 3.4628 - val_accuracy: 0.6265\n",
            "Epoch 122/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 4.4420e-05 - accuracy: 1.0000 - val_loss: 3.4682 - val_accuracy: 0.6265\n",
            "Epoch 123/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 4.3546e-05 - accuracy: 1.0000 - val_loss: 3.4843 - val_accuracy: 0.6265\n",
            "Epoch 124/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.1950e-05 - accuracy: 1.0000 - val_loss: 3.4893 - val_accuracy: 0.6225\n",
            "Epoch 125/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.0977e-05 - accuracy: 1.0000 - val_loss: 3.4986 - val_accuracy: 0.6265\n",
            "Epoch 126/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 4.0248e-05 - accuracy: 1.0000 - val_loss: 3.5098 - val_accuracy: 0.6305\n",
            "Epoch 127/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.8745e-05 - accuracy: 1.0000 - val_loss: 3.4995 - val_accuracy: 0.6305\n",
            "Epoch 128/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.7912e-05 - accuracy: 1.0000 - val_loss: 3.5127 - val_accuracy: 0.6225\n",
            "Epoch 129/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3.6772e-05 - accuracy: 1.0000 - val_loss: 3.5167 - val_accuracy: 0.6225\n",
            "Epoch 130/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.5854e-05 - accuracy: 1.0000 - val_loss: 3.5341 - val_accuracy: 0.6225\n",
            "Epoch 131/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.4970e-05 - accuracy: 1.0000 - val_loss: 3.5318 - val_accuracy: 0.6225\n",
            "Epoch 132/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.4227e-05 - accuracy: 1.0000 - val_loss: 3.5350 - val_accuracy: 0.6225\n",
            "Epoch 133/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.3238e-05 - accuracy: 1.0000 - val_loss: 3.5528 - val_accuracy: 0.6225\n",
            "Epoch 134/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3.2608e-05 - accuracy: 1.0000 - val_loss: 3.5779 - val_accuracy: 0.6305\n",
            "Epoch 135/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.2283e-05 - accuracy: 1.0000 - val_loss: 3.5660 - val_accuracy: 0.6225\n",
            "Epoch 136/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.0843e-05 - accuracy: 1.0000 - val_loss: 3.5725 - val_accuracy: 0.6265\n",
            "Epoch 137/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.9990e-05 - accuracy: 1.0000 - val_loss: 3.5620 - val_accuracy: 0.6305\n",
            "Epoch 138/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.9234e-05 - accuracy: 1.0000 - val_loss: 3.6051 - val_accuracy: 0.6305\n",
            "Epoch 139/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.8724e-05 - accuracy: 1.0000 - val_loss: 3.5845 - val_accuracy: 0.6225\n",
            "Epoch 140/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.8078e-05 - accuracy: 1.0000 - val_loss: 3.5953 - val_accuracy: 0.6265\n",
            "Epoch 141/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.7392e-05 - accuracy: 1.0000 - val_loss: 3.6017 - val_accuracy: 0.6265\n",
            "Epoch 142/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.6452e-05 - accuracy: 1.0000 - val_loss: 3.6153 - val_accuracy: 0.6225\n",
            "Epoch 143/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.5792e-05 - accuracy: 1.0000 - val_loss: 3.6293 - val_accuracy: 0.6225\n",
            "Epoch 144/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.5576e-05 - accuracy: 1.0000 - val_loss: 3.6272 - val_accuracy: 0.6225\n",
            "Epoch 145/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.4588e-05 - accuracy: 1.0000 - val_loss: 3.6326 - val_accuracy: 0.6225\n",
            "Epoch 146/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.4049e-05 - accuracy: 1.0000 - val_loss: 3.6338 - val_accuracy: 0.6265\n",
            "Epoch 147/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.3442e-05 - accuracy: 1.0000 - val_loss: 3.6492 - val_accuracy: 0.6225\n",
            "Epoch 148/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.2811e-05 - accuracy: 1.0000 - val_loss: 3.6341 - val_accuracy: 0.6305\n",
            "Epoch 149/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.2523e-05 - accuracy: 1.0000 - val_loss: 3.6481 - val_accuracy: 0.6305\n",
            "Epoch 150/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.2002e-05 - accuracy: 1.0000 - val_loss: 3.6505 - val_accuracy: 0.6225\n",
            "Epoch 151/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1311e-05 - accuracy: 1.0000 - val_loss: 3.6752 - val_accuracy: 0.6305\n",
            "Epoch 152/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.0721e-05 - accuracy: 1.0000 - val_loss: 3.6816 - val_accuracy: 0.6225\n",
            "Epoch 153/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.0187e-05 - accuracy: 1.0000 - val_loss: 3.6828 - val_accuracy: 0.6225\n",
            "Epoch 154/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.9819e-05 - accuracy: 1.0000 - val_loss: 3.6930 - val_accuracy: 0.6225\n",
            "Epoch 155/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.9310e-05 - accuracy: 1.0000 - val_loss: 3.6987 - val_accuracy: 0.6265\n",
            "Epoch 156/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.8751e-05 - accuracy: 1.0000 - val_loss: 3.6971 - val_accuracy: 0.6225\n",
            "Epoch 157/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.8287e-05 - accuracy: 1.0000 - val_loss: 3.7203 - val_accuracy: 0.6225\n",
            "Epoch 158/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.7919e-05 - accuracy: 1.0000 - val_loss: 3.7273 - val_accuracy: 0.6225\n",
            "Epoch 159/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.7493e-05 - accuracy: 1.0000 - val_loss: 3.7362 - val_accuracy: 0.6305\n",
            "Epoch 160/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.7009e-05 - accuracy: 1.0000 - val_loss: 3.7188 - val_accuracy: 0.6305\n",
            "Epoch 161/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.6813e-05 - accuracy: 1.0000 - val_loss: 3.7276 - val_accuracy: 0.6225\n",
            "Epoch 162/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.6236e-05 - accuracy: 1.0000 - val_loss: 3.7340 - val_accuracy: 0.6265\n",
            "Epoch 163/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.5895e-05 - accuracy: 1.0000 - val_loss: 3.7543 - val_accuracy: 0.6225\n",
            "Epoch 164/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.5507e-05 - accuracy: 1.0000 - val_loss: 3.7485 - val_accuracy: 0.6265\n",
            "Epoch 165/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.5176e-05 - accuracy: 1.0000 - val_loss: 3.7538 - val_accuracy: 0.6225\n",
            "Epoch 166/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.4720e-05 - accuracy: 1.0000 - val_loss: 3.7675 - val_accuracy: 0.6225\n",
            "Epoch 167/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.4392e-05 - accuracy: 1.0000 - val_loss: 3.7706 - val_accuracy: 0.6225\n",
            "Epoch 168/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.4067e-05 - accuracy: 1.0000 - val_loss: 3.7825 - val_accuracy: 0.6225\n",
            "Epoch 169/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.3785e-05 - accuracy: 1.0000 - val_loss: 3.7890 - val_accuracy: 0.6225\n",
            "Epoch 170/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.3434e-05 - accuracy: 1.0000 - val_loss: 3.7917 - val_accuracy: 0.6225\n",
            "Epoch 171/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.3084e-05 - accuracy: 1.0000 - val_loss: 3.7936 - val_accuracy: 0.6225\n",
            "Epoch 172/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2839e-05 - accuracy: 1.0000 - val_loss: 3.8060 - val_accuracy: 0.6225\n",
            "Epoch 173/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.2501e-05 - accuracy: 1.0000 - val_loss: 3.8073 - val_accuracy: 0.6225\n",
            "Epoch 174/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.2225e-05 - accuracy: 1.0000 - val_loss: 3.7993 - val_accuracy: 0.6305\n",
            "Epoch 175/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.1997e-05 - accuracy: 1.0000 - val_loss: 3.8125 - val_accuracy: 0.6305\n",
            "Epoch 176/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1627e-05 - accuracy: 1.0000 - val_loss: 3.8347 - val_accuracy: 0.6225\n",
            "Epoch 177/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1353e-05 - accuracy: 1.0000 - val_loss: 3.8326 - val_accuracy: 0.6265\n",
            "Epoch 178/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.1155e-05 - accuracy: 1.0000 - val_loss: 3.8308 - val_accuracy: 0.6185\n",
            "Epoch 179/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.0881e-05 - accuracy: 1.0000 - val_loss: 3.8527 - val_accuracy: 0.6225\n",
            "Epoch 180/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.0635e-05 - accuracy: 1.0000 - val_loss: 3.8592 - val_accuracy: 0.6225\n",
            "Epoch 181/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.0366e-05 - accuracy: 1.0000 - val_loss: 3.8732 - val_accuracy: 0.6225\n",
            "Epoch 182/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.0128e-05 - accuracy: 1.0000 - val_loss: 3.8712 - val_accuracy: 0.6225\n",
            "Epoch 183/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 9.8957e-06 - accuracy: 1.0000 - val_loss: 3.8673 - val_accuracy: 0.6265\n",
            "Epoch 184/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 9.6801e-06 - accuracy: 1.0000 - val_loss: 3.8653 - val_accuracy: 0.6265\n",
            "Epoch 185/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 9.5468e-06 - accuracy: 1.0000 - val_loss: 3.9023 - val_accuracy: 0.6225\n",
            "Epoch 186/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 9.3614e-06 - accuracy: 1.0000 - val_loss: 3.8963 - val_accuracy: 0.6225\n",
            "Epoch 187/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 9.1091e-06 - accuracy: 1.0000 - val_loss: 3.9030 - val_accuracy: 0.6225\n",
            "Epoch 188/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 8.8414e-06 - accuracy: 1.0000 - val_loss: 3.9077 - val_accuracy: 0.6225\n",
            "Epoch 189/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 8.6220e-06 - accuracy: 1.0000 - val_loss: 3.9021 - val_accuracy: 0.6225\n",
            "Epoch 190/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 8.4187e-06 - accuracy: 1.0000 - val_loss: 3.9046 - val_accuracy: 0.6265\n",
            "Epoch 191/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 8.2218e-06 - accuracy: 1.0000 - val_loss: 3.9244 - val_accuracy: 0.6225\n",
            "Epoch 192/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 8.0602e-06 - accuracy: 1.0000 - val_loss: 3.9220 - val_accuracy: 0.6225\n",
            "Epoch 193/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 7.8919e-06 - accuracy: 1.0000 - val_loss: 3.9434 - val_accuracy: 0.6225\n",
            "Epoch 194/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 7.6878e-06 - accuracy: 1.0000 - val_loss: 3.9399 - val_accuracy: 0.6225\n",
            "Epoch 195/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 7.4917e-06 - accuracy: 1.0000 - val_loss: 3.9548 - val_accuracy: 0.6225\n",
            "Epoch 196/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 7.3085e-06 - accuracy: 1.0000 - val_loss: 3.9554 - val_accuracy: 0.6225\n",
            "Epoch 197/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 7.1678e-06 - accuracy: 1.0000 - val_loss: 3.9592 - val_accuracy: 0.6225\n",
            "Epoch 198/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 7.0121e-06 - accuracy: 1.0000 - val_loss: 3.9647 - val_accuracy: 0.6225\n",
            "Epoch 199/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.8756e-06 - accuracy: 1.0000 - val_loss: 3.9632 - val_accuracy: 0.6265\n",
            "Epoch 200/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.7047e-06 - accuracy: 1.0000 - val_loss: 3.9792 - val_accuracy: 0.6225\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d040ab08670>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e4SXgc6g9YgC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}